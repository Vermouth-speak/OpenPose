import torch.nn as nnimport torchvision.models as modelsimport torchimport randomimport torch.optim as optimfrom dataset import Mydatasetfrom torch.utils.data import DataLoaderfrom tqdm import tqdmimport os#在Pytorch的nn模块中，它是不需要你手动定义网络层的权重和偏置的#获取学习率函数def get_lr(optimizer):    for param_group in optimizer.param_groups:        # optimizer.param_groups是一个list，每一个元素是字典，遍历每一个字典，返回        # optimizer.param_groups[0]：长度为7的字典，包括[‘params’, ‘lr’, ‘betas’, ‘eps’, ‘weight_decay’, ‘amsgrad’, ‘maximize’]这7个参数        # lr是学习率        # 返回学习率        return param_group['lr']#计算准确率函数def metric_func(pred ,lab):    _, index = torch.max(pred, dim=-1) # pred是模型的输出，dim=-1表示删除的是最后一个维度    # torch.max()这个函数返回的是两个值，第一个值是具体的value（我们用下划线_表示），第二个值是value所在的index（也就是predicted）。    acc = torch.where(index == lab, 1., 0.).mean()    # torch.where(condition，a，b) 输入参数condition：条件限制，如果满足条件，则选择a，否则选择b作为输出。    return acc    #返回模型输出和原本图像对比是否准确，准确是1，不准确是0device = torch.device('cuda:0')#torch.device代表将torch.Tensor分配到的设备的对象。torch.device包含一个设备类型（‘cpu’或‘cuda’）和可选的设备序号。#如果设备序号不存在，则为当前设备。如：torch.Tensor用设备构建‘cuda’的结果等同于‘cuda：X’，其中X是torch.cuda.current_device()的结果#加载resnet18模型net = models.resnet18(pretrained=False) # 其中pretrained参数表示是否载入在ImageNet上预训练的模型net.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)#in_channels(int)：输入图像的channel（通道数），out_channels(int)： 输出图像（特征层）的channel# kernel_size(int or tuple)：kernel（卷积核）的大小，tride(int or tuple，optional)： 卷积的步长#padding(int or tuple，optional)：四周pad的大小# bias(bool，optional)：如果是True，则输出的bias可学，默认为True。卷积后是否加偏移量#修改模型最后一层net.fc = nn.Linear(in_features=512, out_features=3755, bias=True)#in_features  输入的神经元个数#out_features 输出神经元个数#bias  是否包含偏置net = net.to(device)#将网络所有成员、函数、操作都搬移到GPU上面。#划分训练和验证比例rate = 0.2"""读取所有训练图像路径，并划分成训练集和验证集"""lines = open('D:/Downloads/OCRCN/hwdb_raw/data/data.txt', 'r').readlines()  # 读取整个文件，并返回列表，一行为一个元素val_lines = random.sample(lines, k=int(len(lines)*rate))  # 返回一个长度为k新列表，新列表存放list所产生k个随机唯一的元素train_lines = list(set(lines)-set(val_lines))  # 训练集为数据集减去测试集# 学习率lr = 2e-3# 设置batchsizebatch_size = 40  # 一次训练所抓取的数据样本数量# 训练集的数量num_train = len(train_lines)# epoch训练次数epoch_step = num_train // batch_size# 设置损失函数:交叉熵损失函数loss_fun = nn.CrossEntropyLoss()# 设置优化器optimizer = optim.Adam(net.parameters(), lr=lr, betas=(0.5, 0.999))# params(iterable)：可用于迭代优化的参数或者定义参数组的dicts。# lr (float, optional) ：学习率(默认: 1e-3)，更新梯度的时候使用# betas (Tuple[float, float], optional)：用于计算梯度的平均和平方的系数(默认: (0.9, 0.999))# 学习率 将输出误差反向传播给网络参数，以此来拟合样本的输出，# 本质上是最优化的一个过程，逐步趋向于最优解，但是每一次更新参数利用多少误差，就需要通过一个参数来确定，这个参数就是学习率，也称步长# 学习率衰减，为了防止学习率过大，在收敛到全局最优点的时候会来回摆荡，所以要让学习率随着训练轮数不断按指数级下降，收敛梯度下降的学习步长。lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.99)  # 学习率衰减"""迭代读取训练数据"""train_data = Mydataset(train_lines, train=True)  # dataset 加载数据的数据集。val_data = Mydataset(val_lines, train=False)train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)  #val_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=False)# dataset：加载的数据集(Dataset对象)  batch_size：batch size shuffle:：是否将数据打乱if __name__ == '__main__':    # 设置迭代次数30次    Epoch = 30    epoch_step = num_train // batch_size  # epoch训练次数    for epoch in range(1, Epoch + 1):        net.train()        total_loss = 0        loss_sum = 0.0        with tqdm(total=epoch_step, desc=f'Epoch {epoch}/{Epoch}', postfix=dict, mininterval=0.3) as pbar:            # tqdm是python的一个关于进度的扩展包，在深度学习过程中可以将训练过程用训练条的形式展示出来，会让训练界面更加美观。            # desc 进度条的前缀            # mininterval 最小的更新时间：0.3seconds            # enumerate用于可迭代对象\可遍历的数据对象组合为一个索引序列，同时列出数据和数据下标，1表示索引从1开始            for step, (features, labels) in enumerate(train_loader, 1):                # features表示图像数据 labels表示标签（tensor对象）                features = features.to(device)                labels = labels.to(device)                batch_size = labels.size()[0]  # labels是一个尺寸为N的张量[N, 1]，其中N等于批次中的样本数                optimizer.zero_grad()  # 梯度初始化为零                out = net(features)  # 前向传播求出预测的值                loss = loss_fun(out, labels)  # 求出损失函数值                loss.backward()  # 反向传播求梯度                optimizer.step()  # 更新所有参数                total_loss += loss # 增加损失函数                # 进度条 显示学习率和损失函数 设置进度条右边显示的信息                pbar.set_postfix(**{'loss': total_loss.item() / (step),                                        'lr': get_lr(optimizer)})                # 每次更新进度条的长度                pbar.update(1)        # 验证        net.eval()        # model.eval() 负责改变batchnorm、dropout的工作方式，如在eval()模式下，dropout是不工作的        acc_sum = 0  # 准确率为0        for val_step, (features, labels) in enumerate(val_loader, 1):            with torch.no_grad():  # 所有计算得出的tensor的requires_grad都自动设置为False                # Tensor有一个requires_grad参数，如果设置为True，则反向传播时，该tensor就会自动求导                # 当requires_grad设置为False时,反向传播时就不会自动求导了，因此大大节约了显存或者说内存                features = features.to(device)                labels = labels.to(device)                predictions = net(features)                val_metric = metric_func(predictions, labels)            acc_sum += val_metric.item()        print('val_acc=%.4f' % (acc_sum / val_step))        # 保存模型        if (epoch) % 1 == 0:            # 存储的是模型的参数            torch.save(net.state_dict(), 'D:/Downloads/OCRCN/logs_handwrite/Epoch%d-Loss%.4f_.pth' % (                epoch, total_loss / (epoch_step + 1)))        lr_scheduler.step()